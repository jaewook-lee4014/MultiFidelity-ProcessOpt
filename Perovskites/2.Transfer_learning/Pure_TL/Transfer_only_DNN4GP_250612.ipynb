{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/MultiFidelity-ProcessOpt/Perovskites/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.mps' has no attribute 'is_available'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA(mps) 사용 가능합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.mps' has no attribute 'is_available'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.mps.is_available():\n",
    "    print(\"CUDA(mps) 사용 가능합니다.\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"CUDA(GPU) 사용 불가, CPU 사용합니다.\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'register_cmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01molympus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01molympus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobjects\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m \tParameterContinuous,\n\u001b[1;32m     12\u001b[0m \tParameterDiscrete, \n\u001b[1;32m     13\u001b[0m \tParameterCategorical, \n\u001b[1;32m     14\u001b[0m \tParameterVector\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01molympus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcampaigns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParameterSpace, Campaign\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/olympus/__init__.py:51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplanners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Planner\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Plotter\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msurfaces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Surface\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnoises\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Noise\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/olympus/plotter/__init__.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m     Plotter \u001b[38;5;241m=\u001b[39m PlotterMatplotlib\n\u001b[1;32m     38\u001b[0m     check_further \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01molympus_colors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_olympus_colors\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# ===============================================================================\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# check for seaborn\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_further:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/olympus/plotter/olympus_colors.py:26\u001b[0m\n\u001b[1;32m     21\u001b[0m _olympus_cmap \u001b[38;5;241m=\u001b[39m LinearSegmentedColormap\u001b[38;5;241m.\u001b[39mfrom_list(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molympus\u001b[39m\u001b[38;5;124m\"\u001b[39m, _olympus_reference_colors)\n\u001b[1;32m     22\u001b[0m _olympus_cmap_r \u001b[38;5;241m=\u001b[39m LinearSegmentedColormap\u001b[38;5;241m.\u001b[39mfrom_list(\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molympus_r\u001b[39m\u001b[38;5;124m\"\u001b[39m, _olympus_reference_colors[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m plt\u001b[38;5;241m.\u001b[39mregister_cmap(cmap\u001b[38;5;241m=\u001b[39m_olympus_cmap)\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mregister_cmap(cmap\u001b[38;5;241m=\u001b[39m_olympus_cmap_r)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_olympus_colors\u001b[39m(n):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'register_cmap'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "from olympus.datasets import Dataset\n",
    "from olympus.objects import (\n",
    "\tParameterContinuous,\n",
    "\tParameterDiscrete, \n",
    "\tParameterCategorical, \n",
    "\tParameterVector\n",
    ")\n",
    "from olympus.campaigns import ParameterSpace, Campaign\n",
    "\n",
    "# from atlas.planners.multi_fidelity.planner import MultiFidelityPlanner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../0.Data/lookup_table.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m NUM_CHEAP \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# lookup table\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# organic --> cation --> anion --> bandgap_hse06/bandgap_gga\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m LOOKUP \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../0.Data/lookup_table.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../0.Data/lookup_table.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_RUNS = 1\n",
    "# BUDGET = 30\n",
    "COST_BUDGET = 50 # 200.\n",
    "NUM_INIT_DESIGN = 10\n",
    "NUM_CHEAP = 8\n",
    "\n",
    "# lookup table\n",
    "# organic --> cation --> anion --> bandgap_hse06/bandgap_gga\n",
    "LOOKUP = pickle.load(open('../0.Data/lookup_table.pkl', 'rb'))\n",
    "# print(lookup.keys())\n",
    "# print(lookup['Ethylammonium']['Ge']['F'].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_from_label(label_arr, s, label_maps, LOOKUP):\n",
    "    \"\"\"\n",
    "    label_arr: [organic_label, cation_label, anion_label]\n",
    "    s: 0.1 or 1.0 (fidelity)\n",
    "    label_maps: {'organic': {...}, 'cation': {...}, 'anion': {...}}\n",
    "    LOOKUP: 전체 lookup table\n",
    "    \"\"\"\n",
    "    # 1. label_maps 역변환 사전 생성\n",
    "    reverse_maps = {\n",
    "        \"organic\": {v: k for k, v in label_maps[\"organic\"].items()},\n",
    "        \"cation\": {v: k for k, v in label_maps[\"cation\"].items()},\n",
    "        \"anion\": {v: k for k, v in label_maps[\"anion\"].items()},\n",
    "    }\n",
    "    # 2. label에서 원래 카테고리명으로 변환\n",
    "    organic = reverse_maps[\"organic\"][int(label_arr[0])]\n",
    "    cation = reverse_maps[\"cation\"][int(label_arr[1])]\n",
    "    anion = reverse_maps[\"anion\"][int(label_arr[2])]\n",
    "\n",
    "    # 3. 기존 measure 함수와 동일\n",
    "    if s == 1.0:\n",
    "        measurement = np.amin(\n",
    "            LOOKUP[organic.capitalize()][cation][anion]['bandgap_hse06']\n",
    "        )\n",
    "    elif s == 0.1:\n",
    "        measurement = np.amin(\n",
    "            LOOKUP[organic.capitalize()][cation][anion]['bandgap_gga']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"s(fidelity)는 0.1 또는 1.0만 가능합니다.\")\n",
    "    return measurement\n",
    "\n",
    "def get_min_hse06_bandgap(param_space):\n",
    "\torganic_options = [o.capitalize() for o in param_space[1].options]\n",
    "\tcation_options = [o.capitalize() for o in param_space[2].options]\n",
    "\tanion_options = [o.capitalize() for o in param_space[3].options]\n",
    "\n",
    "\thse06_bandgaps = []\n",
    "\tfor organic_option in organic_options:\n",
    "\t\tfor cation_option in cation_options:\n",
    "\t\t\tfor anion_option in anion_options:\n",
    "\t\t\t\thse06_bandgaps.append(\n",
    "\t\t\t\t\tnp.amin(\n",
    "\t\t\t\t\t\tLOOKUP[organic_option][cation_option][anion_option]['bandgap_hse06']\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t)\n",
    "\tmin_hse06_bandgap = np.amin(hse06_bandgaps)\n",
    "\treturn min_hse06_bandgap\n",
    "\n",
    "def compute_cost(params):\n",
    "\tcosts = params[:,0].astype(float)\n",
    "\treturn np.sum(costs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class TransferLearningDNN:\n",
    "    def __init__(self, input_dim, hidden_dim=64, device='cpu'):\n",
    "        self.input_dim = input_dim\n",
    "        self.device = device\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.pretrain_losses = []\n",
    "        self.finetune_losses = []\n",
    "\n",
    "        # feature extractor (hidden layers)\n",
    "        self.feature_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "        # 임시 선형 출력층 (bias=False는 선택)\n",
    "        self.out_layer = nn.Linear(hidden_dim, 1, bias=False).to(device)\n",
    "\n",
    "        # 최종 전체 모델\n",
    "        self.model = nn.Sequential(self.feature_net, self.out_layer)\n",
    "\n",
    "        self.feature_net = self.feature_net.float()\n",
    "        self.out_layer = self.out_layer.float()\n",
    "        self.model = self.model.float()\n",
    "\n",
    "    def pretrain(self, X_low, y_low, epochs=50, lr=1e-3, verbose=False):\n",
    "        # low-fidelity 데이터로 선학습\n",
    "        self.pretrain_losses = []\n",
    "        X_low = np.asarray(X_low, dtype=np.float32)  # ★ float32로 강제 변환\n",
    "        y_low = np.asarray(y_low, dtype=np.float32).flatten()  # ★ float32로 강제 변환\n",
    "        X_tensor = torch.tensor(X_low, dtype=torch.float32).to(self.device)\n",
    "        y_tensor = torch.tensor(y_low, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "        optimizer = optim.Adam(list(self.feature_net.parameters()) + list(self.out_layer.parameters()), lr=lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            features = self.feature_net(X_tensor)\n",
    "            pred = self.out_layer(features)\n",
    "            loss = loss_fn(pred, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            self.pretrain_losses.append(loss.item())\n",
    "            if verbose and (epoch+1) % 50 == 0:\n",
    "                print(f'[Pretrain] Epoch {epoch+1}: Loss {loss.item():.4f}')\n",
    "\n",
    "    def finetune(self, X_high, y_high, epochs=50, lr=1e-4, verbose=False):\n",
    "        self.finetune_losses = []\n",
    "        X_high = np.asarray(X_high, dtype=np.float32)  # ★ float32로 강제 변환\n",
    "        y_high = np.asarray(y_high, dtype=np.float32).flatten()  # ★ float32로 강제 변환\n",
    "        X_tensor = torch.tensor(X_high, dtype=torch.float32).to(self.device)\n",
    "        y_tensor = torch.tensor(y_high, dtype=torch.float32).view(-1, 1).to(self.device)\n",
    "        optimizer = optim.Adam(list(self.feature_net.parameters()) + list(self.out_layer.parameters()), lr=lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            features = self.feature_net(X_tensor)\n",
    "            pred = self.out_layer(features)\n",
    "            loss = loss_fn(pred, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            self.finetune_losses.append(loss.item())\n",
    "            if verbose and (epoch+1) % 20 == 0:\n",
    "                print(f'[Finetune] Epoch {epoch+1}: Loss {loss.item():.4f}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=np.float32)  # ★ float32로 강제 변환\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            features = self.feature_net(X_tensor)\n",
    "            y_pred = self.out_layer(features).cpu().numpy().flatten()\n",
    "        return y_pred\n",
    "\n",
    "    def extract_features(self, X):\n",
    "        X = np.asarray(X, dtype=np.float32)  # ★ float32로 강제 변환\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            features = self.feature_net(X_tensor).cpu().numpy()\n",
    "        return features\n",
    "\n",
    "\n",
    "    def get_fitness_func(self, y_best=None, xi=0.01):\n",
    "        def fitness(x):\n",
    "            mu = self.predict(np.array([x]))[0]\n",
    "            if y_best is not None:\n",
    "                return -(y_best - mu - xi)  # maximize EI → minimize -EI\n",
    "            else:\n",
    "                return mu\n",
    "        return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organic': {'ethylammonium': 1,\n",
       "  'propylammonium': 2,\n",
       "  'butylammonium': 3,\n",
       "  'isopropylammonium': 4,\n",
       "  'dimethylammonium': 5,\n",
       "  'acetamidinium': 6,\n",
       "  'methylammonium': 7,\n",
       "  'guanidinium': 8,\n",
       "  'hydroxylammonium': 9,\n",
       "  'formamidinium': 10,\n",
       "  'tetramethylammonium': 11,\n",
       "  'hydrazinium': 12,\n",
       "  'ammonium': 13,\n",
       "  'trimethylammonium': 14,\n",
       "  'azetidinium': 15,\n",
       "  'imidazolium': 16},\n",
       " 'cation': {'Ge': 1, 'Sn': 2, 'Pb': 3},\n",
       " 'anion': {'F': 1, 'Cl': 2, 'Br': 3, 'I': 4}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_space = {\n",
    "    \"organic\": [\n",
    "        \"ethylammonium\", \"propylammonium\", \"butylammonium\", \"isopropylammonium\",\n",
    "        \"dimethylammonium\", \"acetamidinium\", \"methylammonium\", \"guanidinium\",\n",
    "        \"hydroxylammonium\", \"formamidinium\", \"tetramethylammonium\", \"hydrazinium\",\n",
    "        \"ammonium\", \"trimethylammonium\", \"azetidinium\", \"imidazolium\"\n",
    "    ],\n",
    "    \"cation\": [\"Ge\", \"Sn\", \"Pb\"],\n",
    "    \"anion\": [\"F\", \"Cl\", \"Br\", \"I\"]\n",
    "}\n",
    "label_maps = {\n",
    "    key: {val: idx for idx, val in enumerate(vals, 1)}   # 1부터 시작하고 싶으면 enumerate(..., 1)\n",
    "    for key, vals in param_space.items()\n",
    "}\n",
    "label_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_param_space(param_space, n_samples, random_state=None):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    param_names = list(param_space.keys())\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        sample = {}\n",
    "        for key, opts in param_space.items():\n",
    "            if isinstance(opts, (list, tuple)) and len(opts) > 0 and isinstance(opts[0], (str, int)):  # 범주형\n",
    "                sample[key] = rng.choice(opts)\n",
    "            elif isinstance(opts, tuple) and len(opts) == 2 and all(isinstance(x, (int, float)) for x in opts):  # 연속형\n",
    "                low, high = opts\n",
    "                sample[key] = float(rng.uniform(low, high))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown parameter type for {key}: {opts}\")\n",
    "        samples.append(sample)\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'organic': 'propylammonium', 'cation': 'Pb', 'anion': 'Br'}\n",
      "{'organic': 'guanidinium', 'cation': 'Sn', 'anion': 'I'}\n",
      "{'organic': 'propylammonium', 'cation': 'Pb', 'anion': 'F'}\n",
      "{'organic': 'propylammonium', 'cation': 'Sn', 'anion': 'I'}\n",
      "{'organic': 'hydrazinium', 'cation': 'Pb', 'anion': 'Br'}\n",
      "{'organic': 'ammonium', 'cation': 'Sn', 'anion': 'F'}\n",
      "{'organic': 'trimethylammonium', 'cation': 'Sn', 'anion': 'Br'}\n",
      "{'organic': 'acetamidinium', 'cation': 'Ge', 'anion': 'I'}\n",
      "{'organic': 'ammonium', 'cation': 'Sn', 'anion': 'Cl'}\n",
      "{'organic': 'trimethylammonium', 'cation': 'Sn', 'anion': 'Cl'}\n"
     ]
    }
   ],
   "source": [
    "# NUM_INIT_DESIGN = 10  # 원하는 개수로 지정\n",
    "\n",
    "# param_space는 이전 단계에서 정의한 딕셔너리 그대로 사용\n",
    "\n",
    "init_samples = sample_param_space(param_space, NUM_INIT_DESIGN, random_state=42)\n",
    "for s in init_samples:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': {'organic': 'propylammonium', 'cation': 'Pb', 'anion': 'Br'},\n",
       "  's': 0.1,\n",
       "  'measurement': 2.1145},\n",
       " {'params': {'organic': 'guanidinium', 'cation': 'Sn', 'anion': 'I'},\n",
       "  's': 0.1,\n",
       "  'measurement': 1.0856},\n",
       " {'params': {'organic': 'propylammonium', 'cation': 'Pb', 'anion': 'F'},\n",
       "  's': 1.0,\n",
       "  'measurement': 5.2155},\n",
       " {'params': {'organic': 'propylammonium', 'cation': 'Sn', 'anion': 'I'},\n",
       "  's': 0.1,\n",
       "  'measurement': 1.3516},\n",
       " {'params': {'organic': 'hydrazinium', 'cation': 'Pb', 'anion': 'Br'},\n",
       "  's': 0.1,\n",
       "  'measurement': 2.3859},\n",
       " {'params': {'organic': 'ammonium', 'cation': 'Sn', 'anion': 'F'},\n",
       "  's': 0.1,\n",
       "  'measurement': 3.8068},\n",
       " {'params': {'organic': 'trimethylammonium', 'cation': 'Sn', 'anion': 'Br'},\n",
       "  's': 0.1,\n",
       "  'measurement': 1.7405},\n",
       " {'params': {'organic': 'acetamidinium', 'cation': 'Ge', 'anion': 'I'},\n",
       "  's': 0.1,\n",
       "  'measurement': 1.6986},\n",
       " {'params': {'organic': 'ammonium', 'cation': 'Sn', 'anion': 'Cl'},\n",
       "  's': 0.1,\n",
       "  'measurement': 1.8983},\n",
       " {'params': {'organic': 'trimethylammonium', 'cation': 'Sn', 'anion': 'Cl'},\n",
       "  's': 0.1,\n",
       "  'measurement': 2.2948}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_fidelities(n_samples, high_ratio=0.11111, random_state=None):\n",
    "    \"\"\"\n",
    "    전체 n_samples 중 high_ratio 만큼만 high-fidelity(1.0), 나머지는 low-fidelity(0.1)로 할당\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n_high = max(1, int(round(n_samples * high_ratio)))\n",
    "    n_low = n_samples - n_high\n",
    "    fids = [1.0]*n_high + [0.1]*n_low\n",
    "    rng.shuffle(fids)\n",
    "    return fids\n",
    "\n",
    "measurements = []\n",
    "for params, s in zip(init_samples, assign_fidelities(NUM_INIT_DESIGN, high_ratio=0.11111, random_state=42)):\n",
    "    if s == 1.0:\n",
    "        measurement = np.amin(\n",
    "            LOOKUP[params['organic'].capitalize()][params['cation']][params['anion']]['bandgap_hse06']\n",
    "        )\n",
    "    else:\n",
    "        measurement = np.amin(\n",
    "            LOOKUP[params['organic'].capitalize()][params['cation']][params['anion']]['bandgap_gga']\n",
    "        )\n",
    "    # 관측값 저장\n",
    "    measurements.append({\"params\": params, \"s\": s, \"measurement\": measurement})\n",
    "measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.1, 1.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_fidelities(NUM_INIT_DESIGN, high_ratio=0.11111, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.   3.   3.   0.1]\n",
      " [ 8.   2.   4.   0.1]\n",
      " [ 2.   3.   1.   1. ]\n",
      " [ 2.   2.   4.   0.1]\n",
      " [12.   3.   3.   0.1]]\n",
      "[2.1145 1.0856 5.2155 1.3516 2.3859]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 라벨맵 생성\n",
    "label_maps = {\n",
    "    key: {val: idx for idx, val in enumerate(vals, 1)}   # 1부터 시작\n",
    "    for key, vals in param_space.items()\n",
    "}\n",
    "\n",
    "# 2. df 변환 및 라벨 적용\n",
    "df = pd.DataFrame([\n",
    "    {**obs['params'], 's': obs['s'], 'measurement': obs['measurement']}\n",
    "    for obs in measurements\n",
    "])\n",
    "for col in ['organic', 'cation', 'anion']:\n",
    "    df[col + '_label'] = df[col].map(label_maps[col])\n",
    "\n",
    "# 3. 모델 입력/출력 분리\n",
    "ini_X = df[['organic_label', 'cation_label', 'anion_label', 's']].values\n",
    "ini_y = df['measurement'].values\n",
    "\n",
    "print(ini_X[:5])\n",
    "print(ini_y[:5])\n",
    "\n",
    "# s 값에 따라 분할\n",
    "ini_X_low = ini_X[df['s'] == 0.1]\n",
    "ini_y_low = ini_y[df['s'] == 0.1]\n",
    "\n",
    "ini_X_high = ini_X[df['s'] == 1.0]\n",
    "ini_y_high = ini_y[df['s'] == 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pretrain] Epoch 50: Loss 0.3992\n",
      "[Pretrain] Epoch 100: Loss 0.2799\n",
      "[Finetune] Epoch 20: Loss 2.7000\n",
      "[Finetune] Epoch 40: Loss 0.0963\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ini_X_low, ini_X_high에서 s를 제외한 3개 컬럼만 남기기\n",
    "ini_X_low = ini_X_low[:, :3]   # (N_low, 3)\n",
    "ini_X_high = ini_X_high[:, :3] # (N_high, 3)\n",
    "ini_X_low = np.asarray(ini_X_low, dtype=np.float32)\n",
    "ini_X_high = np.asarray(ini_X_high, dtype=np.float32)\n",
    "ini_y_low = np.asarray(ini_y_low, dtype=np.float32).flatten()\n",
    "ini_y_high = np.asarray(ini_y_high, dtype=np.float32).flatten()\n",
    "\n",
    "# 모델 학습\n",
    "model = TransferLearningDNN(input_dim=ini_X_low.shape[1], hidden_dim=64, device='cpu')\n",
    "\n",
    "if len(ini_X_low) > 0:\n",
    "    model.pretrain(ini_X_low, ini_y_low, epochs=100, lr=1e-3, verbose=True)\n",
    "\n",
    "if len(ini_X_high) > 0:\n",
    "    model.finetune(ini_X_high, ini_y_high, epochs=50, lr=1e-3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_measurement_to_data(existing_X_low, existing_y_low,\n",
    "                               existing_X_high, existing_y_high,\n",
    "                               label_arr, s, label_maps, LOOKUP):\n",
    "    \"\"\"\n",
    "    label_arr: [organic_label, cation_label, anion_label]\n",
    "    s: 0.1 or 1.0 (fidelity)\n",
    "    기존 데이터에 label_arr을 s에 따라 붙여주는 함수\n",
    "    \"\"\"\n",
    "    # 1. 측정값 구하기\n",
    "    measurement = measure_from_label(label_arr, s, label_maps, LOOKUP)\n",
    "    \n",
    "    # 2. 데이터 추가 (s는 X에 넣지 않으므로 3개만!)\n",
    "    label_arr = np.array(label_arr, dtype=np.float32).reshape(1, -1)\n",
    "    measurement = np.array([measurement], dtype=np.float32)\n",
    "\n",
    "    if s == 0.1:\n",
    "        existing_X_low = np.vstack([existing_X_low, label_arr]) if existing_X_low.size else label_arr\n",
    "        existing_y_low = np.concatenate([existing_y_low, measurement]) if existing_y_low.size else measurement\n",
    "    elif s == 1.0:\n",
    "        existing_X_high = np.vstack([existing_X_high, label_arr]) if existing_X_high.size else label_arr\n",
    "        existing_y_high = np.concatenate([existing_y_high, measurement]) if existing_y_high.size else measurement\n",
    "    else:\n",
    "        raise ValueError(\"s(fidelity)는 0.1 또는 1.0만 가능합니다.\")\n",
    "\n",
    "    return existing_X_low, existing_y_low, existing_X_high, existing_y_high\n",
    "\n",
    "# # 추천 label이 [2, 3, 3], s=1.0이라고 가정\n",
    "# ini_X_low, ini_y_low, ini_X_high, ini_y_high = append_measurement_to_data(\n",
    "#     ini_X_low, ini_y_low, ini_X_high, ini_y_high,\n",
    "#     next_x_label, 1.0, label_maps, LOOKUP\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN4GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정지조건추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLinearRegression:\n",
    "    def __init__(self, alpha=1.0, beta=25.0):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    def fit(self, Phi, y):\n",
    "        I = np.eye(Phi.shape[1])\n",
    "        self.K = self.beta * Phi.T @ Phi + self.alpha * I\n",
    "        self.K_inv = np.linalg.inv(self.K)\n",
    "        self.m = self.beta * self.K_inv @ Phi.T @ y\n",
    "    def predict(self, phi_x):\n",
    "        mean = phi_x @ self.m\n",
    "        var = phi_x @ self.K_inv @ phi_x.T + 1 / self.beta\n",
    "        return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combo</th>\n",
       "      <th>bandgap_hse06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,1,1</td>\n",
       "      <td>5.3704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,1,2</td>\n",
       "      <td>3.1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1,1,3</td>\n",
       "      <td>2.7138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,1,4</td>\n",
       "      <td>2.2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,2,1</td>\n",
       "      <td>3.9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>16,2,4</td>\n",
       "      <td>1.9179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>16,3,1</td>\n",
       "      <td>4.4501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>16,3,2</td>\n",
       "      <td>3.6158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>16,3,3</td>\n",
       "      <td>2.8641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>16,3,4</td>\n",
       "      <td>2.3480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      combo  bandgap_hse06\n",
       "0     1,1,1         5.3704\n",
       "1     1,1,2         3.1393\n",
       "2     1,1,3         2.7138\n",
       "3     1,1,4         2.2338\n",
       "4     1,2,1         3.9789\n",
       "..      ...            ...\n",
       "187  16,2,4         1.9179\n",
       "188  16,3,1         4.4501\n",
       "189  16,3,2         3.6158\n",
       "190  16,3,3         2.8641\n",
       "191  16,3,4         2.3480\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "LOOKUP = pickle.load(open('../0.Data/lookup_table.pkl', 'rb'))\n",
    "\n",
    "organic_options = ['ethylammonium', 'propylammonium', 'butylammonium', 'isopropylammonium', 'dimethylammonium', 'acetamidinium', 'methylammonium', 'guanidinium', 'hydroxylammonium', 'formamidinium', 'tetramethylammonium', 'hydrazinium', 'ammonium', 'trimethylammonium', 'azetidinium', 'imidazolium']\n",
    "cation_options = ['Ge', 'Sn', 'Pb']\n",
    "anion_options = ['F', 'Cl', 'Br', 'I']\n",
    "\n",
    "all_results = []\n",
    "for i, organic in enumerate(organic_options, 1):\n",
    "    for j, cation in enumerate(cation_options, 1):\n",
    "        for k, anion in enumerate(anion_options, 1):\n",
    "            try:\n",
    "                bandgap = np.amin(\n",
    "                    LOOKUP[organic.capitalize()][cation][anion]['bandgap_hse06']\n",
    "                )\n",
    "                combo_label = f\"{i},{j},{k}\"\n",
    "                all_results.append({\n",
    "                    'combo': combo_label,\n",
    "                    'bandgap_hse06': bandgap\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Skip: {organic}-{cation}-{anion} ({e})\")\n",
    "                continue\n",
    "\n",
    "ori_gga_data = pd.DataFrame(all_results)\n",
    "ori_gga_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest bandgap_hse06: 1.5249 (combo: 12,2,4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'12,2,4'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_idx = ori_gga_data['bandgap_hse06'].idxmin()\n",
    "min_combo = ori_gga_data.loc[min_idx, 'combo']\n",
    "min_bandgap = ori_gga_data.loc[min_idx, 'bandgap_hse06']\n",
    "print(f\"Lowest bandgap_hse06: {min_bandgap:.4f} (combo: {min_combo})\")\n",
    "min_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def penalized_expected_improvement(mu, sigma, y_best, xi=0.01, penalty_scale=1.0, penalty_width=0.1):\n",
    "    # 기본 EI 계산\n",
    "    sigma = np.maximum(sigma, 1e-8)\n",
    "    z = (y_best - mu - xi) / sigma\n",
    "    ei = (y_best - mu - xi) * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "    # y_best 근처면 penalty 부여\n",
    "    penalty = np.exp(-((mu - y_best)**2) / (2 * penalty_width**2))\n",
    "    penalized_ei = ei - penalty_scale * penalty\n",
    "    return penalized_ei\n",
    "\n",
    "def expected_improvement(mu, sigma, y_best, xi=0.01):\n",
    "    sigma = np.maximum(sigma, 1e-8)\n",
    "    z = (y_best - mu - xi) / sigma\n",
    "    ei = (y_best - mu - xi) * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "    return ei\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "init_samples = sample_param_space(param_space, NUM_INIT_DESIGN, random_state=42)\n",
    "init_fids = assign_fidelities(NUM_INIT_DESIGN, high_ratio=0.2, random_state=42)\n",
    "measurements = []\n",
    "for params, s in zip(init_samples, init_fids):\n",
    "    measurement = measure_from_label(\n",
    "        [label_maps['organic'][params['organic']],\n",
    "         label_maps['cation'][params['cation']],\n",
    "         label_maps['anion'][params['anion']]],\n",
    "        s, label_maps, LOOKUP\n",
    "    )\n",
    "    measurements.append({\"params\": params, \"s\": s, \"measurement\": measurement})\n",
    "\n",
    "# 데이터프레임 변환 및 라벨 적용\n",
    "df = pd.DataFrame([\n",
    "    {**obs['params'], 's': obs['s'], 'measurement': obs['measurement']}\n",
    "    for obs in measurements\n",
    "])\n",
    "for col in ['organic', 'cation', 'anion']:\n",
    "    df[col + '_label'] = df[col].map(label_maps[col])\n",
    "\n",
    "ini_X = df[['organic_label', 'cation_label', 'anion_label', 's']].values\n",
    "ini_y = df['measurement'].values\n",
    "\n",
    "# s 값에 따라 분할 (X에서 s를 제거)\n",
    "ini_X_low = ini_X[df['s'] == 0.1][:, :3]\n",
    "ini_y_low = ini_y[df['s'] == 0.1]\n",
    "ini_X_high = ini_X[df['s'] == 1.0][:, :3]\n",
    "ini_y_high = ini_y[df['s'] == 1.0]\n",
    "\n",
    "param_ranges = [\n",
    "    range(1, 17),  # organic_label: 1~16\n",
    "    range(1, 4),   # cation_label: 1~3\n",
    "    range(1, 5),   # anion_label: 1~4\n",
    "]\n",
    "\n",
    "min_hse06_bandgap = 1.5249\n",
    "COST_BUDGET = 50\n",
    "\n",
    "\n",
    "timing_data = []\n",
    "cost_data = []\n",
    "best_so_far_curve = []\n",
    "total_cost = 0.0\n",
    "best_so_far = np.inf\n",
    "# N_ITER = 10 # 원하는 반복 횟수\n",
    "iter_ = 0\n",
    "all_results = []\n",
    "\n",
    "cumulative_cost_list = []\n",
    "for _ in range(100):\n",
    "    s= 0.1\n",
    "    while total_cost < COST_BUDGET:\n",
    "    # for iter_ in range(N_ITER):\n",
    "        iter_ += 1\n",
    "        print(f\"\\n==== Iteration {iter_} ====\")\n",
    "        iter_start = time.time()   # ★★★ 타이밍 시작\n",
    "        \n",
    "        model = TransferLearningDNN(input_dim=3, hidden_dim=64, device='cpu')\n",
    "        if len(ini_X_low) > 0:\n",
    "            model.pretrain(ini_X_low, ini_y_low, epochs=300, lr=1e-3, verbose=False)\n",
    "        if len(ini_X_high) > 0:\n",
    "            model.finetune(ini_X_high, ini_y_high, epochs=150, lr=1e-3, verbose=False)\n",
    "        \n",
    "        # BLR 학습\n",
    "        X_all = np.vstack([ini_X_low, ini_X_high])\n",
    "        y_all = np.concatenate([ini_y_low, ini_y_high])\n",
    "        features_all = model.extract_features(X_all)\n",
    "        blr = BayesianLinearRegression(alpha=1.0, beta=25.0)\n",
    "        blr.fit(features_all, y_all)\n",
    "        \n",
    "        # (2) 전체 조합 생성 (192개)\n",
    "        all_combinations = list(itertools.product(*param_ranges))  # shape=(192, 3)\n",
    "        X_grid = np.array(all_combinations, dtype=np.float32)\n",
    "        features_grid = model.extract_features(X_grid)\n",
    "\n",
    "\n",
    "        # (3) BLR 예측 및 EI 계산\n",
    "        y_pred = []\n",
    "        y_std = []\n",
    "        for phi in features_grid:\n",
    "            mu, var = blr.predict(phi)\n",
    "            y_pred.append(mu)\n",
    "            y_std.append(np.sqrt(var))\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_std = np.array(y_std)\n",
    "        \n",
    "        y_best = np.min(y_all)\n",
    "        \n",
    "        # Calculate EI for all points\n",
    "        ei = expected_improvement(y_pred, y_std, y_best)\n",
    "        \n",
    "        # Set EI to 0 for already explored points\n",
    "        if s == 0.1:\n",
    "            train_combo_set = set(tuple(map(int, row)) for row in np.vstack([ini_X_low, ini_X_high]))\n",
    "            for i, combo in enumerate(X_grid.astype(int)):\n",
    "                if tuple(combo) in train_combo_set:\n",
    "                    ei[i] = 0.0\n",
    "        elif s == 1:\n",
    "            train_combo_set = set(tuple(map(int, row)) for row in ini_X_high)\n",
    "            print(train_combo_set)\n",
    "            for i, combo in enumerate(X_grid.astype(int)):\n",
    "                if tuple(combo) in train_combo_set:\n",
    "                    ei[i] = 0.0\n",
    "                    \n",
    "        # Find best unexplored point\n",
    "        best_idx = np.argmax(ei)\n",
    "        next_x_label = list(X_grid[best_idx].astype(int))\n",
    "        print(\"EI-based recommended label:\", next_x_label)\n",
    "\n",
    "        ori_gga_data['y_pred'] = y_pred\n",
    "        ori_gga_data['y_std'] = y_std\n",
    "        \n",
    "        # 학습에 사용된 조합 set 만들기 (int 변환!)\n",
    "        train_combo_set = set(tuple(map(int, row)) for row in np.vstack([ini_X_low, ini_X_high]))\n",
    "\n",
    "        # 전체 192개 조합 중 학습에 쓰인 인덱스 찾기\n",
    "        train_indices = [i for i, combo in enumerate(X_grid.astype(int)) if tuple(combo) in train_combo_set]\n",
    "\n",
    "\n",
    "        # ori_gga_data, y_pred, y_std, ei 등 위에서처럼 준비됐다고 가정\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(18, 7))\n",
    "        x_idx = range(len(ori_gga_data))\n",
    "\n",
    "        # True / 예측 / Uncertainty\n",
    "        ax1.scatter(x_idx, ori_gga_data['bandgap_hse06'], s=40, label='True bandgap', color='royalblue')\n",
    "        ax1.scatter(x_idx, ori_gga_data['y_pred'], s=40, label='BLR prediction', color='orange', alpha=0.7)\n",
    "        ax1.fill_between(\n",
    "            x_idx,\n",
    "            ori_gga_data['y_pred'] - ori_gga_data['y_std'],\n",
    "            ori_gga_data['y_pred'] + ori_gga_data['y_std'],\n",
    "            color='orange', alpha=0.2, label='Pred. std. dev.'\n",
    "        )\n",
    "        # 학습 포인트(누적) 검정색으로!\n",
    "        # === Training points (low/high) ===\n",
    "        train_indices_low = [i for i, combo in enumerate(X_grid.astype(int)) if tuple(combo) in set(tuple(map(int, row)) for row in ini_X_low)]\n",
    "        train_indices_high = [i for i, combo in enumerate(X_grid.astype(int)) if tuple(combo) in set(tuple(map(int, row)) for row in ini_X_high)]\n",
    "\n",
    "        # low fidelity (s=0.1): 파란색 삼각형\n",
    "        ax1.scatter(\n",
    "            train_indices_low, ori_gga_data['bandgap_hse06'].iloc[train_indices_low],\n",
    "            s=110, color='black', label='Training (low, s=0.1)', zorder=10, marker='^'\n",
    "        )\n",
    "        # high fidelity (s=1.0): 빨간색 동그라미\n",
    "        ax1.scatter(\n",
    "            train_indices_high, ori_gga_data['bandgap_hse06'].iloc[train_indices_high],\n",
    "            s=110, color='crimson', label='Training (high, s=1.0)', zorder=10, marker='^'\n",
    "        )\n",
    "\n",
    "        # === Global optimal 별표 ===\n",
    "        optimal_combo = '12,2,4'\n",
    "        optimal_idx = ori_gga_data.index[ori_gga_data['combo'] == optimal_combo].tolist()[0]\n",
    "        optimal_bandgap = ori_gga_data.loc[optimal_idx, 'bandgap_hse06']\n",
    "        ax1.scatter(\n",
    "            optimal_idx, optimal_bandgap,\n",
    "            marker='*', color='purple', s=250, edgecolor='black',\n",
    "            label='Global optimum', zorder=20\n",
    "        )\n",
    "\n",
    "        ax1.set_ylabel('Bandgap (hse06)', color='navy')\n",
    "        ax1.set_xlabel('Combinations (organic, cation, anion)')\n",
    "        ax1.set_xticks(x_idx)\n",
    "        ax1.set_xticklabels(ori_gga_data['combo'], rotation=90, fontsize=7)\n",
    "\n",
    "        # 제목 강조: s==1일 때 색상 강조\n",
    "        if (iter_ % 8 == 0):\n",
    "            ax1.set_title(f'True Bandgap, Prediction, Uncertainty, and EI\\niter: {iter_}',\n",
    "                          color='crimson', fontsize=18, fontweight='bold', backgroundcolor='#ffe6e6')\n",
    "        else:\n",
    "            ax1.set_title(f'True Bandgap, Prediction, Uncertainty, and EI\\niter: {iter_}')\n",
    "        ax1.tick_params(axis='y', labelcolor='navy')\n",
    "\n",
    "        # EI 오른쪽축\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(x_idx, ei, marker='o', color='forestgreen', label='EI', linewidth=2)\n",
    "        ax2.scatter(best_idx, ei[best_idx], color='red', s=120, zorder=15, label='Recommended (max EI)')\n",
    "        ax2.set_ylabel('Expected Improvement (EI)', color='forestgreen')\n",
    "        ax2.tick_params(axis='y', labelcolor='forestgreen')\n",
    "\n",
    "        # 범례\n",
    "        h1, l1 = ax1.get_legend_handles_labels()\n",
    "        h2, l2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(h1+h2, l1+l2, loc='upper right')\n",
    "\n",
    "        plt.xlim(-1, len(ori_gga_data))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # 실제값과 예측값\n",
    "        y_true = ori_gga_data['bandgap_hse06'].values\n",
    "        y_pred = ori_gga_data['y_pred'].values\n",
    "\n",
    "        # R², MAE 계산\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "        print(f\"R² score: {r2:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        \n",
    "        y_true = ori_gga_data['bandgap_hse06'].values\n",
    "        y_pred = ori_gga_data['y_pred'].values\n",
    "\n",
    "        # 2. 학습 데이터 인덱스\n",
    "        train_indices = set([i for i, combo in enumerate(X_grid.astype(int)) if tuple(combo) in train_combo_set])\n",
    "        all_indices = set(range(len(y_true)))\n",
    "        non_train_indices = all_indices - train_indices\n",
    "\n",
    "        # 3. 산점도\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        # (1) 비학습 데이터 (연한색)\n",
    "        plt.scatter(\n",
    "            y_true[list(non_train_indices)], y_pred[list(non_train_indices)],\n",
    "            alpha=0.4, s=40, color='grey', label='Unmeasured (candidates)'\n",
    "        )\n",
    "        # (2) 학습 데이터 (진한색)\n",
    "        plt.scatter(\n",
    "            y_true[list(train_indices)], y_pred[list(train_indices)],\n",
    "            alpha=0.9, s=80, color='black', label='Training points', edgecolor='w'\n",
    "        )\n",
    "        # (3) 기준선\n",
    "        plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', label='Ideal: y=x')\n",
    "\n",
    "        plt.xlabel('Actual value')\n",
    "        plt.ylabel('Predicted value')\n",
    "        plt.title(f'Actual vs. Predicted\\nR²: {r2:.3f}, MAE: {mae:.3f}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        # (4) Fidelity 할당 (예시: 8:1)\n",
    "        s = 0.1 if (iter_ % 8 != 0) else 1.0\n",
    "        # (5) 측정 및 데이터 추가\n",
    "        measurement = measure_from_label(next_x_label, s, label_maps, LOOKUP)\n",
    "        ini_X_low, ini_y_low, ini_X_high, ini_y_high = append_measurement_to_data(\n",
    "            ini_X_low, ini_y_low, ini_X_high, ini_y_high,\n",
    "            next_x_label, s, label_maps, LOOKUP\n",
    "        )\n",
    "        print(f\"Measurement: {measurement:.4f} (fidelity={s})\")\n",
    "        \n",
    "        iter_end = time.time()\n",
    "        time_taken = iter_end - iter_start\n",
    "        timing_data.append([0, iter_, time_taken])\n",
    "        total_cost += s\n",
    "        cost_data.append([0, iter_, total_cost])\n",
    "        \n",
    "        # best-so-far 기록\n",
    "        if s == 1:\n",
    "            if measurement < best_so_far:\n",
    "                best_so_far = measurement\n",
    "        best_so_far_curve.append([0, iter_, s, best_so_far])\n",
    "        print(f\"Cumulative cost: {total_cost}, best_so_far: {best_so_far}\")\n",
    "        if s == 1.0 and np.isclose(measurement, min_hse06_bandgap, atol=1e-6):\n",
    "            print('found the min hse06 bandgap!')\n",
    "            break\n",
    "    break\n",
    "    cumulative_cost_list.append(total_cost)\n",
    "\n",
    "\n",
    "# 전체 타이밍 데이터 저장\n",
    "# timing_df = pd.DataFrame(timing_data, columns=['run_ix', 'iter', 'time_taken'])\n",
    "# timing_df.to_csv('TL_timing_results.csv', index=False)\n",
    "\n",
    "# # 누적 실험비용 저장\n",
    "# cost_df = pd.DataFrame(cost_data, columns=['run_ix', 'iter', 'cumulative_cost'])\n",
    "# cost_df.to_csv('TL_cumulative_cost.csv', index=False)\n",
    "\n",
    "# # best-so-far curve 저장 (regret curve)\n",
    "# best_so_far_df = pd.DataFrame(best_so_far_curve, columns=['run_ix', 'iter', 's', 'best_so_far'])\n",
    "# best_so_far_df.to_csv('TL_best_so_far_curve.csv', index=False)\n",
    "\n",
    "# df_results = pd.DataFrame(all_results)\n",
    "# df_results.to_csv(\"TL_all_iter_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(ini_X_low, ini_y_low, ini_X_high, ini_y_high, device='cpu'):\n",
    "    model = TransferLearningDNN(input_dim=3, hidden_dim=64, device=device)\n",
    "    if len(ini_X_low) > 0:\n",
    "        model.pretrain(ini_X_low, ini_y_low, epochs=300, lr=1e-3, verbose=False)\n",
    "    if len(ini_X_high) > 0:\n",
    "        model.finetune(ini_X_high, ini_y_high, epochs=150, lr=1e-3, verbose=False)\n",
    "    return model\n",
    "\n",
    "def fit_blr(model, ini_X_low, ini_X_high, ini_y_low, ini_y_high):\n",
    "    X_all = np.vstack([ini_X_low, ini_X_high])\n",
    "    y_all = np.concatenate([ini_y_low, ini_y_high])\n",
    "    features_all = model.extract_features(X_all)\n",
    "    blr = BayesianLinearRegression(alpha=1.0, beta=25.0)\n",
    "    blr.fit(features_all, y_all)\n",
    "    return blr, X_all, y_all\n",
    "\n",
    "def recommend_next(model, blr, param_ranges, ini_X_low, ini_X_high, ini_y_low, ini_y_high, s):\n",
    "    # 1. 모든 가능한 조합 생성\n",
    "    all_combinations = list(itertools.product(*param_ranges))\n",
    "    X_grid = np.array(all_combinations, dtype=np.float32)\n",
    "    \n",
    "    # 2. DNN으로 feature 추출\n",
    "    features_grid = model.extract_features(X_grid)\n",
    "    \n",
    "    # 3. BLR로 예측값과 불확실성 계산\n",
    "    y_pred, y_std = [], []\n",
    "    for phi in features_grid:\n",
    "        mu, var = blr.predict(phi)\n",
    "        y_pred.append(mu)\n",
    "        y_std.append(np.sqrt(var))\n",
    "    y_pred, y_std = np.array(y_pred), np.array(y_std)\n",
    "    \n",
    "    # 4. EI 계산을 위한 현재까지의 최적값 (high-fidelity 데이터만 사용)\n",
    "    y_best = np.min(ini_y_high) if len(ini_y_high) > 0 else np.inf\n",
    "    \n",
    "    # 5. Expected Improvement 계산\n",
    "    ei = expected_improvement(y_pred, y_std, y_best)\n",
    "    \n",
    "    # 6. s에 따라 이미 실험한 점 처리\n",
    "    if s == 1.0:  # high-fidelity\n",
    "        # high-fidelity로 실험한 점만 제외\n",
    "        train_combo_set = set(tuple(map(int, row)) for row in ini_X_high)\n",
    "    else:  # low-fidelity\n",
    "        # 모든 실험점 제외 (low + high)\n",
    "        train_combo_set = set(tuple(map(int, row)) for row in np.vstack([ini_X_low, ini_X_high]))\n",
    "    \n",
    "    for i, combo in enumerate(X_grid.astype(int)):\n",
    "        if tuple(combo) in train_combo_set:\n",
    "            ei[i] = 0.0\n",
    "            \n",
    "    # 7. EI가 최대인 점 선택\n",
    "    best_idx = np.argmax(ei)\n",
    "    next_x_label = list(X_grid[best_idx].astype(int))\n",
    "    \n",
    "    return next_x_label, y_pred, y_std, ei, best_idx, X_grid\n",
    "\n",
    "def plot_iteration(ori_gga_data, y_pred, y_std, ei, best_idx, X_grid, ini_X_low, ini_X_high, iter_, label_maps):\n",
    "        # 데이터를 bandgap_hse06 기준으로 정렬\n",
    "    ori_gga_data = ori_gga_data.sort_values('bandgap_hse06')\n",
    "    \n",
    "    # 정렬된 인덱스에 맞춰 ei도 재정렬\n",
    "    ei = ei[ori_gga_data.index]\n",
    "    \n",
    "    # 학습에 사용된 조합 set 만들기 (int 변환!)\n",
    "    train_combo_set = set(tuple(map(int, row)) for row in np.vstack([ini_X_low, ini_X_high]))\n",
    "\n",
    "    # 전체 192개 조합 중 학습에 쓰인 인덱스 찾기 (정렬된 인덱스 기준)\n",
    "    train_indices = [i for i, combo in enumerate(X_grid[ori_gga_data.index].astype(int)) \n",
    "                    if tuple(combo) in train_combo_set]\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(18, 7))\n",
    "    x_idx = range(len(ori_gga_data))\n",
    "\n",
    "    # True / 예측 / Uncertainty\n",
    "    ax1.scatter(x_idx, ori_gga_data['bandgap_hse06'], s=40, label='True bandgap', color='royalblue')\n",
    "    ax1.scatter(x_idx, ori_gga_data['y_pred'], s=40, label='BLR prediction', color='orange', alpha=0.7)\n",
    "    ax1.fill_between(\n",
    "        x_idx,\n",
    "        ori_gga_data['y_pred'] - ori_gga_data['y_std'],\n",
    "        ori_gga_data['y_pred'] + ori_gga_data['y_std'],\n",
    "        color='orange', alpha=0.2, label='Pred. std. dev.'\n",
    "    )\n",
    "\n",
    "    # 학습 포인트(누적) - 정렬된 인덱스 기준으로 찾기\n",
    "    train_indices_low = [i for i, combo in enumerate(X_grid[ori_gga_data.index].astype(int)) \n",
    "                        if tuple(combo) in set(tuple(map(int, row)) for row in ini_X_low)]\n",
    "    train_indices_high = [i for i, combo in enumerate(X_grid[ori_gga_data.index].astype(int)) \n",
    "                         if tuple(combo) in set(tuple(map(int, row)) for row in ini_X_high)]\n",
    "\n",
    "    # low fidelity (s=0.1): 파란색 삼각형\n",
    "    ax1.scatter(\n",
    "        train_indices_low, ori_gga_data['bandgap_hse06'].iloc[train_indices_low],\n",
    "        s=110, color='black', label='Training (low, s=0.1)', zorder=10, marker='^'\n",
    "    )\n",
    "    # high fidelity (s=1.0): 빨간색 동그라미\n",
    "    ax1.scatter(\n",
    "        train_indices_high, ori_gga_data['bandgap_hse06'].iloc[train_indices_high],\n",
    "        s=110, color='crimson', label='Training (high, s=1.0)', zorder=10, marker='^'\n",
    "    )\n",
    "\n",
    "    # Global optimal 별표 (정렬된 인덱스에서 찾기)\n",
    "    optimal_combo = '12,2,4'\n",
    "    optimal_idx = ori_gga_data.index[ori_gga_data['combo'] == optimal_combo].tolist()[0]\n",
    "    optimal_idx_in_sorted = ori_gga_data.index.get_loc(optimal_idx)  # 정렬된 위치 찾기\n",
    "    optimal_bandgap = ori_gga_data.loc[optimal_idx, 'bandgap_hse06']\n",
    "    ax1.scatter(\n",
    "        optimal_idx_in_sorted, optimal_bandgap,\n",
    "        marker='*', color='purple', s=250, edgecolor='black',\n",
    "        label='Global optimum', zorder=20\n",
    "    )\n",
    "\n",
    "    ax1.set_ylabel('Bandgap (hse06)', color='navy')\n",
    "    ax1.set_xlabel('Combinations (organic, cation, anion)')\n",
    "    ax1.set_xticks(x_idx)\n",
    "    ax1.set_xticklabels(ori_gga_data['combo'], rotation=90, fontsize=7)\n",
    "\n",
    "    # 제목 강조\n",
    "    if (iter_ % 8 == 0):\n",
    "        ax1.set_title(f'True Bandgap (sorted), Prediction, Uncertainty, and EI\\niter: {iter_}',\n",
    "                      color='crimson', fontsize=18, fontweight='bold', backgroundcolor='#ffe6e6')\n",
    "    else:\n",
    "        ax1.set_title(f'True Bandgap (sorted), Prediction, Uncertainty, and EI\\niter: {iter_}')\n",
    "    ax1.tick_params(axis='y', labelcolor='navy')\n",
    "\n",
    "    # EI 오른쪽축\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(x_idx, ei, marker='o', color='forestgreen', label='EI', linewidth=2)\n",
    "    # best_idx도 정렬된 인덱스에 맞춰 변환\n",
    "    best_idx_in_sorted = ori_gga_data.index.get_loc(best_idx)\n",
    "    ax2.scatter(best_idx_in_sorted, ei[best_idx], color='red', s=120, zorder=15, label='Recommended (max EI)')\n",
    "    ax2.set_ylabel('Expected Improvement (EI)', color='forestgreen')\n",
    "    ax2.tick_params(axis='y', labelcolor='forestgreen')\n",
    "\n",
    "    # 범례\n",
    "    h1, l1 = ax1.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(h1+h2, l1+l2, loc='upper right')\n",
    "\n",
    "    plt.xlim(-1, len(ori_gga_data))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # 실제값과 예측값\n",
    "    y_true = ori_gga_data['bandgap_hse06'].values\n",
    "    y_pred = ori_gga_data['y_pred'].values\n",
    "\n",
    "    # R², MAE 계산\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    print(f\"R² score: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    \n",
    "    y_true = ori_gga_data['bandgap_hse06'].values\n",
    "    y_pred = ori_gga_data['y_pred'].values\n",
    "\n",
    "    # 2. 학습 데이터 인덱스\n",
    "    train_indices = set([i for i, combo in enumerate(X_grid.astype(int)) if tuple(combo) in train_combo_set])\n",
    "    all_indices = set(range(len(y_true)))\n",
    "    non_train_indices = all_indices - train_indices\n",
    "\n",
    "    # 3. 산점도\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    # (1) 비학습 데이터 (연한색)\n",
    "    plt.scatter(\n",
    "        y_true[list(non_train_indices)], y_pred[list(non_train_indices)],\n",
    "        alpha=0.4, s=40, color='grey', label='Unmeasured (candidates)'\n",
    "    )\n",
    "    # (2) 학습 데이터 (진한색)\n",
    "    plt.scatter(\n",
    "        y_true[list(train_indices)], y_pred[list(train_indices)],\n",
    "        alpha=0.9, s=80, color='black', label='Training points', edgecolor='w'\n",
    "    )\n",
    "    # (3) 기준선\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', label='Ideal: y=x')\n",
    "\n",
    "    plt.xlabel('Actual value')\n",
    "    plt.ylabel('Predicted value')\n",
    "    plt.title(f'Actual vs. Predicted\\nR²: {r2:.3f}, MAE: {mae:.3f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_param_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m init_samples \u001b[38;5;241m=\u001b[39m sample_param_space(param_space, NUM_INIT_DESIGN, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m init_fids \u001b[38;5;241m=\u001b[39m assign_fidelities(NUM_INIT_DESIGN, high_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m measurements \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_param_space' is not defined"
     ]
    }
   ],
   "source": [
    "init_samples = sample_param_space(param_space, NUM_INIT_DESIGN, random_state=42)\n",
    "init_fids = assign_fidelities(NUM_INIT_DESIGN, high_ratio=0.2, random_state=42)\n",
    "measurements = []\n",
    "for params, s in zip(init_samples, init_fids):\n",
    "    measurement = measure_from_label(\n",
    "        [label_maps['organic'][params['organic']],\n",
    "         label_maps['cation'][params['cation']],\n",
    "         label_maps['anion'][params['anion']]],\n",
    "        s, label_maps, LOOKUP\n",
    "    )\n",
    "    measurements.append({\"params\": params, \"s\": s, \"measurement\": measurement})\n",
    "\n",
    "# 데이터프레임 변환 및 라벨 적용\n",
    "df = pd.DataFrame([\n",
    "    {**obs['params'], 's': obs['s'], 'measurement': obs['measurement']}\n",
    "    for obs in measurements\n",
    "])\n",
    "for col in ['organic', 'cation', 'anion']:\n",
    "    df[col + '_label'] = df[col].map(label_maps[col])\n",
    "\n",
    "ini_X = df[['organic_label', 'cation_label', 'anion_label', 's']].values\n",
    "ini_y = df['measurement'].values\n",
    "\n",
    "# s 값에 따라 분할 (X에서 s를 제거)\n",
    "ini_X_low = ini_X[df['s'] == 0.1][:, :3]\n",
    "ini_y_low = ini_y[df['s'] == 0.1]\n",
    "ini_X_high = ini_X[df['s'] == 1.0][:, :3]\n",
    "ini_y_high = ini_y[df['s'] == 1.0]\n",
    "\n",
    "param_ranges = [\n",
    "    range(1, 17),  # organic_label: 1~16\n",
    "    range(1, 4),   # cation_label: 1~3\n",
    "    range(1, 5),   # anion_label: 1~4\n",
    "]\n",
    "\n",
    "min_hse06_bandgap = 1.5249\n",
    "COST_BUDGET = 50\n",
    "timing_data = []  # 각 iteration의 시간 기록\n",
    "cost_data = []    # 누적 비용 기록\n",
    "best_so_far_curve = []  # iteration별 best_so_far 기록\n",
    "total_cost = 0.0  # 누적 비용\n",
    "best_so_far = np.inf  # 현재까지 관측된 최소값 (high-fidelity)\n",
    "iter_ = 0\n",
    "while total_cost < COST_BUDGET:\n",
    "    iter_ += 1\n",
    "    print(f\"\\n==== Iteration {iter_} ====\")\n",
    "    iter_start = time.time()\n",
    "    # 8번 중 1번만 high-fidelity(비용 1.0), 나머지는 low-fidelity(비용 0.1)\n",
    "    s = 0.1 if (iter_ % 8 != 0) else 1.0\n",
    "\n",
    "    # DNN+BLR 모델 학습\n",
    "    model = train_model(ini_X_low, ini_y_low, ini_X_high, ini_y_high)\n",
    "\n",
    "    # BLR 적합 (feature 추출 및 BLR 학습)\n",
    "    blr, X_all, y_all = fit_blr(model, ini_X_low, ini_X_high, ini_y_low, ini_y_high)\n",
    "\n",
    "    # 다음 실험 추천 (EI 최대화)\n",
    "    next_x_label, y_pred, y_std, ei, best_idx, X_grid = recommend_next(\n",
    "        model, blr, param_ranges, ini_X_low, ini_X_high, ini_y_low, ini_y_high, s\n",
    "    )\n",
    "    \n",
    "    # 현재 iteration의 예측 결과 시각화\n",
    "    plot_iteration(ori_gga_data, y_pred, y_std, ei, best_idx, X_grid, ini_X_low, ini_X_high, iter_, label_maps)\n",
    "    # 실제 측정값 얻기 (실험 시뮬레이션)\n",
    "    measurement = measure_from_label(next_x_label, s, label_maps, LOOKUP)\n",
    "    # 측정값을 데이터에 추가\n",
    "    ini_X_low, ini_y_low, ini_X_high, ini_y_high = append_measurement_to_data(\n",
    "        ini_X_low, ini_y_low, ini_X_high, ini_y_high,\n",
    "        next_x_label, s, label_maps, LOOKUP\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print(f\"Measurement: {measurement:.4f} (fidelity={s})\")\n",
    "    \n",
    "    iter_end = time.time()\n",
    "    time_taken = iter_end - iter_start\n",
    "    timing_data.append([0, iter_, time_taken])  # 시간 기록\n",
    "    total_cost += s  # 비용 누적\n",
    "    cost_data.append([0, iter_, total_cost])  # 비용 기록\n",
    "    # high-fidelity 측정값이 더 작으면 best_so_far 갱신\n",
    "    if s == 1:\n",
    "        if measurement < best_so_far:\n",
    "            best_so_far = measurement\n",
    "    best_so_far_curve.append([0, iter_, s, best_so_far])  # best_so_far 기록\n",
    "    print(f\"Cumulative cost: {total_cost}, best_so_far: {best_so_far}\")\n",
    "\n",
    "    # 최소 bandgap을 찾으면 조기 종료\n",
    "    if s == 1.0 and np.isclose(measurement, min_hse06_bandgap, atol=1e-6):\n",
    "        print('found the min hse06 bandgap!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과기록용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Starting Run 1/100 =====\n",
      "Run 1: Found the min hse06 bandgap!\n",
      "Run 1 completed. Final total_cost: 39.10\n",
      "\n",
      "===== Starting Run 2/100 =====\n",
      "Run 2: Found the min hse06 bandgap!\n",
      "Run 2 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 3/100 =====\n",
      "Run 3: Found the min hse06 bandgap!\n",
      "Run 3 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 4/100 =====\n",
      "Run 4: Found the min hse06 bandgap!\n",
      "Run 4 completed. Final total_cost: 6.80\n",
      "\n",
      "===== Starting Run 5/100 =====\n",
      "Run 5: Found the min hse06 bandgap!\n",
      "Run 5 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 6/100 =====\n",
      "Run 6: Found the min hse06 bandgap!\n",
      "Run 6 completed. Final total_cost: 40.80\n",
      "\n",
      "===== Starting Run 7/100 =====\n",
      "Run 7: Found the min hse06 bandgap!\n",
      "Run 7 completed. Final total_cost: 25.50\n",
      "\n",
      "===== Starting Run 8/100 =====\n",
      "Run 8: Found the min hse06 bandgap!\n",
      "Run 8 completed. Final total_cost: 6.80\n",
      "\n",
      "===== Starting Run 9/100 =====\n",
      "Run 9: Found the min hse06 bandgap!\n",
      "Run 9 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 10/100 =====\n",
      "Run 10: Found the min hse06 bandgap!\n",
      "Run 10 completed. Final total_cost: 13.60\n",
      "\n",
      "===== Starting Run 11/100 =====\n",
      "Run 11 completed. Final total_cost: 50.00\n",
      "\n",
      "===== Starting Run 12/100 =====\n",
      "Run 12: Found the min hse06 bandgap!\n",
      "Run 12 completed. Final total_cost: 39.10\n",
      "\n",
      "===== Starting Run 13/100 =====\n",
      "Run 13: Found the min hse06 bandgap!\n",
      "Run 13 completed. Final total_cost: 17.00\n",
      "\n",
      "===== Starting Run 14/100 =====\n",
      "Run 14: Found the min hse06 bandgap!\n",
      "Run 14 completed. Final total_cost: 35.70\n",
      "\n",
      "===== Starting Run 15/100 =====\n",
      "Run 15: Found the min hse06 bandgap!\n",
      "Run 15 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 16/100 =====\n",
      "Run 16: Found the min hse06 bandgap!\n",
      "Run 16 completed. Final total_cost: 35.70\n",
      "\n",
      "===== Starting Run 17/100 =====\n",
      "Run 17: Found the min hse06 bandgap!\n",
      "Run 17 completed. Final total_cost: 37.40\n",
      "\n",
      "===== Starting Run 18/100 =====\n",
      "Run 18: Found the min hse06 bandgap!\n",
      "Run 18 completed. Final total_cost: 1.70\n",
      "\n",
      "===== Starting Run 19/100 =====\n",
      "Run 19: Found the min hse06 bandgap!\n",
      "Run 19 completed. Final total_cost: 1.70\n",
      "\n",
      "===== Starting Run 20/100 =====\n",
      "Run 20: Found the min hse06 bandgap!\n",
      "Run 20 completed. Final total_cost: 13.60\n",
      "\n",
      "===== Starting Run 21/100 =====\n",
      "Run 21: Found the min hse06 bandgap!\n",
      "Run 21 completed. Final total_cost: 34.00\n",
      "\n",
      "===== Starting Run 22/100 =====\n",
      "Run 22: Found the min hse06 bandgap!\n",
      "Run 22 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 23/100 =====\n",
      "Run 23: Found the min hse06 bandgap!\n",
      "Run 23 completed. Final total_cost: 34.00\n",
      "\n",
      "===== Starting Run 24/100 =====\n",
      "Run 24: Found the min hse06 bandgap!\n",
      "Run 24 completed. Final total_cost: 25.50\n",
      "\n",
      "===== Starting Run 25/100 =====\n",
      "Run 25: Found the min hse06 bandgap!\n",
      "Run 25 completed. Final total_cost: 5.10\n",
      "\n",
      "===== Starting Run 26/100 =====\n",
      "Run 26: Found the min hse06 bandgap!\n",
      "Run 26 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 27/100 =====\n",
      "Run 27: Found the min hse06 bandgap!\n",
      "Run 27 completed. Final total_cost: 25.50\n",
      "\n",
      "===== Starting Run 28/100 =====\n",
      "Run 28: Found the min hse06 bandgap!\n",
      "Run 28 completed. Final total_cost: 39.10\n",
      "\n",
      "===== Starting Run 29/100 =====\n",
      "Run 29: Found the min hse06 bandgap!\n",
      "Run 29 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 30/100 =====\n",
      "Run 30: Found the min hse06 bandgap!\n",
      "Run 30 completed. Final total_cost: 35.70\n",
      "\n",
      "===== Starting Run 31/100 =====\n",
      "Run 31: Found the min hse06 bandgap!\n",
      "Run 31 completed. Final total_cost: 35.70\n",
      "\n",
      "===== Starting Run 32/100 =====\n",
      "Run 32: Found the min hse06 bandgap!\n",
      "Run 32 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 33/100 =====\n",
      "Run 33: Found the min hse06 bandgap!\n",
      "Run 33 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 34/100 =====\n",
      "Run 34: Found the min hse06 bandgap!\n",
      "Run 34 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 35/100 =====\n",
      "Run 35: Found the min hse06 bandgap!\n",
      "Run 35 completed. Final total_cost: 17.00\n",
      "\n",
      "===== Starting Run 36/100 =====\n",
      "Run 36: Found the min hse06 bandgap!\n",
      "Run 36 completed. Final total_cost: 11.90\n",
      "\n",
      "===== Starting Run 37/100 =====\n",
      "Run 37: Found the min hse06 bandgap!\n",
      "Run 37 completed. Final total_cost: 34.00\n",
      "\n",
      "===== Starting Run 38/100 =====\n",
      "Run 38: Found the min hse06 bandgap!\n",
      "Run 38 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 39/100 =====\n",
      "Run 39: Found the min hse06 bandgap!\n",
      "Run 39 completed. Final total_cost: 3.40\n",
      "\n",
      "===== Starting Run 40/100 =====\n",
      "Run 40: Found the min hse06 bandgap!\n",
      "Run 40 completed. Final total_cost: 10.20\n",
      "\n",
      "===== Starting Run 41/100 =====\n",
      "Run 41: Found the min hse06 bandgap!\n",
      "Run 41 completed. Final total_cost: 13.60\n",
      "\n",
      "===== Starting Run 42/100 =====\n",
      "Run 42 completed. Final total_cost: 50.00\n",
      "\n",
      "===== Starting Run 43/100 =====\n",
      "Run 43: Found the min hse06 bandgap!\n",
      "Run 43 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 44/100 =====\n",
      "Run 44: Found the min hse06 bandgap!\n",
      "Run 44 completed. Final total_cost: 39.10\n",
      "\n",
      "===== Starting Run 45/100 =====\n",
      "Run 45: Found the min hse06 bandgap!\n",
      "Run 45 completed. Final total_cost: 17.00\n",
      "\n",
      "===== Starting Run 46/100 =====\n",
      "Run 46: Found the min hse06 bandgap!\n",
      "Run 46 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 47/100 =====\n",
      "Run 47: Found the min hse06 bandgap!\n",
      "Run 47 completed. Final total_cost: 35.70\n",
      "\n",
      "===== Starting Run 48/100 =====\n",
      "Run 48: Found the min hse06 bandgap!\n",
      "Run 48 completed. Final total_cost: 40.80\n",
      "\n",
      "===== Starting Run 49/100 =====\n",
      "Run 49: Found the min hse06 bandgap!\n",
      "Run 49 completed. Final total_cost: 39.10\n",
      "\n",
      "===== Starting Run 50/100 =====\n",
      "Run 50: Found the min hse06 bandgap!\n",
      "Run 50 completed. Final total_cost: 10.20\n",
      "\n",
      "===== Starting Run 51/100 =====\n",
      "Run 51: Found the min hse06 bandgap!\n",
      "Run 51 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 52/100 =====\n",
      "Run 52: Found the min hse06 bandgap!\n",
      "Run 52 completed. Final total_cost: 28.90\n",
      "\n",
      "===== Starting Run 53/100 =====\n",
      "Run 53: Found the min hse06 bandgap!\n",
      "Run 53 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 54/100 =====\n",
      "Run 54: Found the min hse06 bandgap!\n",
      "Run 54 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 55/100 =====\n",
      "Run 55: Found the min hse06 bandgap!\n",
      "Run 55 completed. Final total_cost: 23.80\n",
      "\n",
      "===== Starting Run 56/100 =====\n",
      "Run 56: Found the min hse06 bandgap!\n",
      "Run 56 completed. Final total_cost: 6.80\n",
      "\n",
      "===== Starting Run 57/100 =====\n",
      "Run 57: Found the min hse06 bandgap!\n",
      "Run 57 completed. Final total_cost: 20.40\n",
      "\n",
      "===== Starting Run 58/100 =====\n",
      "Run 58: Found the min hse06 bandgap!\n",
      "Run 58 completed. Final total_cost: 28.90\n",
      "\n",
      "===== Starting Run 59/100 =====\n",
      "Run 59: Found the min hse06 bandgap!\n",
      "Run 59 completed. Final total_cost: 13.60\n",
      "\n",
      "===== Starting Run 60/100 =====\n",
      "Run 60: Found the min hse06 bandgap!\n",
      "Run 60 completed. Final total_cost: 34.00\n",
      "\n",
      "===== Starting Run 61/100 =====\n",
      "Run 61: Found the min hse06 bandgap!\n",
      "Run 61 completed. Final total_cost: 37.40\n",
      "\n",
      "===== Starting Run 62/100 =====\n",
      "Run 62: Found the min hse06 bandgap!\n",
      "Run 62 completed. Final total_cost: 20.40\n",
      "\n",
      "===== Starting Run 63/100 =====\n",
      "Run 63: Found the min hse06 bandgap!\n",
      "Run 63 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 64/100 =====\n",
      "Run 64: Found the min hse06 bandgap!\n",
      "Run 64 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 65/100 =====\n",
      "Run 65: Found the min hse06 bandgap!\n",
      "Run 65 completed. Final total_cost: 18.70\n",
      "\n",
      "===== Starting Run 66/100 =====\n",
      "Run 66: Found the min hse06 bandgap!\n",
      "Run 66 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 67/100 =====\n",
      "Run 67: Found the min hse06 bandgap!\n",
      "Run 67 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 68/100 =====\n",
      "Run 68: Found the min hse06 bandgap!\n",
      "Run 68 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 69/100 =====\n",
      "Run 69: Found the min hse06 bandgap!\n",
      "Run 69 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 70/100 =====\n",
      "Run 70: Found the min hse06 bandgap!\n",
      "Run 70 completed. Final total_cost: 28.90\n",
      "\n",
      "===== Starting Run 71/100 =====\n",
      "Run 71: Found the min hse06 bandgap!\n",
      "Run 71 completed. Final total_cost: 34.00\n",
      "\n",
      "===== Starting Run 72/100 =====\n",
      "Run 72: Found the min hse06 bandgap!\n",
      "Run 72 completed. Final total_cost: 20.40\n",
      "\n",
      "===== Starting Run 73/100 =====\n",
      "Run 73: Found the min hse06 bandgap!\n",
      "Run 73 completed. Final total_cost: 13.60\n",
      "\n",
      "===== Starting Run 74/100 =====\n",
      "Run 74: Found the min hse06 bandgap!\n",
      "Run 74 completed. Final total_cost: 34.00\n",
      "\n",
      "===== Starting Run 75/100 =====\n",
      "Run 75: Found the min hse06 bandgap!\n",
      "Run 75 completed. Final total_cost: 25.50\n",
      "\n",
      "===== Starting Run 76/100 =====\n",
      "Run 76: Found the min hse06 bandgap!\n",
      "Run 76 completed. Final total_cost: 20.40\n",
      "\n",
      "===== Starting Run 77/100 =====\n",
      "Run 77: Found the min hse06 bandgap!\n",
      "Run 77 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 78/100 =====\n",
      "Run 78: Found the min hse06 bandgap!\n",
      "Run 78 completed. Final total_cost: 27.20\n",
      "\n",
      "===== Starting Run 79/100 =====\n",
      "Run 79: Found the min hse06 bandgap!\n",
      "Run 79 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 80/100 =====\n",
      "Run 80: Found the min hse06 bandgap!\n",
      "Run 80 completed. Final total_cost: 28.90\n",
      "\n",
      "===== Starting Run 81/100 =====\n",
      "Run 81: Found the min hse06 bandgap!\n",
      "Run 81 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 82/100 =====\n",
      "Run 82: Found the min hse06 bandgap!\n",
      "Run 82 completed. Final total_cost: 8.50\n",
      "\n",
      "===== Starting Run 83/100 =====\n",
      "Run 83: Found the min hse06 bandgap!\n",
      "Run 83 completed. Final total_cost: 34.00\n",
      "\n",
      "===== Starting Run 84/100 =====\n",
      "Run 84: Found the min hse06 bandgap!\n",
      "Run 84 completed. Final total_cost: 27.20\n",
      "\n",
      "===== Starting Run 85/100 =====\n",
      "Run 85: Found the min hse06 bandgap!\n",
      "Run 85 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 86/100 =====\n",
      "Run 86: Found the min hse06 bandgap!\n",
      "Run 86 completed. Final total_cost: 1.70\n",
      "\n",
      "===== Starting Run 87/100 =====\n",
      "Run 87: Found the min hse06 bandgap!\n",
      "Run 87 completed. Final total_cost: 35.70\n",
      "\n",
      "===== Starting Run 88/100 =====\n",
      "Run 88: Found the min hse06 bandgap!\n",
      "Run 88 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 89/100 =====\n",
      "Run 89: Found the min hse06 bandgap!\n",
      "Run 89 completed. Final total_cost: 25.50\n",
      "\n",
      "===== Starting Run 90/100 =====\n",
      "Run 90: Found the min hse06 bandgap!\n",
      "Run 90 completed. Final total_cost: 40.80\n",
      "\n",
      "===== Starting Run 91/100 =====\n",
      "Run 91: Found the min hse06 bandgap!\n",
      "Run 91 completed. Final total_cost: 28.90\n",
      "\n",
      "===== Starting Run 92/100 =====\n",
      "Run 92: Found the min hse06 bandgap!\n",
      "Run 92 completed. Final total_cost: 30.60\n",
      "\n",
      "===== Starting Run 93/100 =====\n",
      "Run 93: Found the min hse06 bandgap!\n",
      "Run 93 completed. Final total_cost: 28.90\n",
      "\n",
      "===== Starting Run 94/100 =====\n",
      "Run 94: Found the min hse06 bandgap!\n",
      "Run 94 completed. Final total_cost: 1.70\n",
      "\n",
      "===== Starting Run 95/100 =====\n",
      "Run 95: Found the min hse06 bandgap!\n",
      "Run 95 completed. Final total_cost: 39.10\n",
      "\n",
      "===== Starting Run 96/100 =====\n",
      "Run 96: Found the min hse06 bandgap!\n",
      "Run 96 completed. Final total_cost: 23.80\n",
      "\n",
      "===== Starting Run 97/100 =====\n",
      "Run 97: Found the min hse06 bandgap!\n",
      "Run 97 completed. Final total_cost: 32.30\n",
      "\n",
      "===== Starting Run 98/100 =====\n",
      "Run 98: Found the min hse06 bandgap!\n",
      "Run 98 completed. Final total_cost: 25.50\n",
      "\n",
      "===== Starting Run 99/100 =====\n",
      "Run 99: Found the min hse06 bandgap!\n",
      "Run 99 completed. Final total_cost: 39.10\n",
      "\n",
      "===== Starting Run 100/100 =====\n",
      "Run 100: Found the min hse06 bandgap!\n",
      "Run 100 completed. Final total_cost: 30.60\n",
      "\n",
      "All runs completed. Results saved to 'transfer_learning_costs.csv'\n"
     ]
    }
   ],
   "source": [
    "# 100번의 독립적인 런을 위한 결과 저장 리스트\n",
    "all_runs_costs = []\n",
    "\n",
    "for run in range(100):\n",
    "    print(f\"\\n===== Starting Run {run+1}/100 =====\")\n",
    "    \n",
    "    # 초기화\n",
    "    init_samples = sample_param_space(param_space, NUM_INIT_DESIGN, random_state=run)  # 각 런마다 다른 random_state\n",
    "    init_fids = assign_fidelities(NUM_INIT_DESIGN, high_ratio=0.2, random_state=run)\n",
    "    measurements = []\n",
    "    for params, s in zip(init_samples, init_fids):\n",
    "        measurement = measure_from_label(\n",
    "            [label_maps['organic'][params['organic']],\n",
    "             label_maps['cation'][params['cation']],\n",
    "             label_maps['anion'][params['anion']]],\n",
    "            s, label_maps, LOOKUP\n",
    "        )\n",
    "        measurements.append({\"params\": params, \"s\": s, \"measurement\": measurement})\n",
    "\n",
    "    # 데이터프레임 변환 및 초기 데이터 설정\n",
    "    df = pd.DataFrame([\n",
    "        {**obs['params'], 's': obs['s'], 'measurement': obs['measurement']}\n",
    "        for obs in measurements\n",
    "    ])\n",
    "    for col in ['organic', 'cation', 'anion']:\n",
    "        df[col + '_label'] = df[col].map(label_maps[col])\n",
    "\n",
    "    ini_X = df[['organic_label', 'cation_label', 'anion_label', 's']].values\n",
    "    ini_y = df['measurement'].values\n",
    "\n",
    "    ini_X_low = ini_X[df['s'] == 0.1][:, :3]\n",
    "    ini_y_low = ini_y[df['s'] == 0.1]\n",
    "    ini_X_high = ini_X[df['s'] == 1.0][:, :3]\n",
    "    ini_y_high = ini_y[df['s'] == 1.0]\n",
    "\n",
    "    # 각 런의 변수 초기화\n",
    "    total_cost = 0.0\n",
    "    best_so_far = np.inf\n",
    "    iter_ = 0\n",
    "    \n",
    "    while total_cost < COST_BUDGET:\n",
    "        iter_ += 1\n",
    "        s = 0.1 if (iter_ % 8 != 0) else 1.0\n",
    "\n",
    "        # DNN+BLR 모델 학습\n",
    "        model = train_model(ini_X_low, ini_y_low, ini_X_high, ini_y_high)\n",
    "        blr, X_all, y_all = fit_blr(model, ini_X_low, ini_X_high, ini_y_low, ini_y_high)\n",
    "        \n",
    "        # 다음 실험 추천\n",
    "        next_x_label, y_pred, y_std, ei, best_idx, X_grid = recommend_next(\n",
    "            model, blr, param_ranges, ini_X_low, ini_X_high, ini_y_low, ini_y_high, s\n",
    "        )\n",
    "        \n",
    "        # 측정 및 데이터 업데이트\n",
    "        measurement = measure_from_label(next_x_label, s, label_maps, LOOKUP)\n",
    "        ini_X_low, ini_y_low, ini_X_high, ini_y_high = append_measurement_to_data(\n",
    "            ini_X_low, ini_y_low, ini_X_high, ini_y_high,\n",
    "            next_x_label, s, label_maps, LOOKUP\n",
    "        )\n",
    "\n",
    "        total_cost += s\n",
    "        \n",
    "        # high-fidelity 측정값이 더 작으면 best_so_far 갱신\n",
    "        if s == 1.0:\n",
    "            if measurement < best_so_far:\n",
    "                best_so_far = measurement\n",
    "                \n",
    "        # 최소 bandgap을 찾으면 조기 종료\n",
    "        if s == 1.0 and np.isclose(measurement, min_hse06_bandgap, atol=1e-6):\n",
    "            print(f'Run {run+1}: Found the min hse06 bandgap!')\n",
    "            break\n",
    "    \n",
    "    # 각 런이 끝날 때 total_cost 저장\n",
    "    all_runs_costs.append(total_cost)\n",
    "    print(f\"Run {run+1} completed. Final total_cost: {total_cost:.2f}\")\n",
    "\n",
    "# 모든 런이 끝난 후 결과를 CSV로 저장\n",
    "results_df = pd.DataFrame({\n",
    "    'run': range(1, 101),\n",
    "    'total_cost': all_runs_costs\n",
    "})\n",
    "results_df.to_csv('transfer_learning_costs.csv', index=False)\n",
    "print(\"\\nAll runs completed. Results saved to 'transfer_learning_costs.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ori_gga_data: combo, bandgap가 있는 DataFrame\n",
    "np.random.seed(42)  # 재현성\n",
    "\n",
    "# 전체 조합 (192, 3)\n",
    "all_combinations = list(itertools.product(*param_ranges))  # param_ranges는 [range(1,17), range(1,4), range(1,5)]\n",
    "X_grid = np.array(all_combinations, dtype=np.float32)\n",
    "\n",
    "# 랜덤 100개 추출\n",
    "idx_sample = np.random.choice(len(ori_gga_data), size=30, replace=False)\n",
    "ori_sample = ori_gga_data.iloc[idx_sample]\n",
    "\n",
    "# (추출된 조합을 array 형태로 만들기)\n",
    "X_train = np.array([list(map(int, combo.split(','))) for combo in ori_sample['combo']])\n",
    "y_train = ori_sample['bandgap'].values\n",
    "# DNN+BLR\n",
    "model = TransferLearningDNN(input_dim=3, hidden_dim=64, device='cpu')\n",
    "model.pretrain(X_train, y_train, epochs=300, lr=1e-3, verbose=True)\n",
    "# high-fidelity 데이터만 쓸 경우 finetune 생략 가능\n",
    "\n",
    "features_train = model.extract_features(X_train)\n",
    "blr = BayesianLinearRegression(alpha=1.0, beta=25.0)\n",
    "blr.fit(features_train, y_train)\n",
    "features_grid = model.extract_features(X_grid)\n",
    "\n",
    "y_pred = []\n",
    "y_std = []\n",
    "for phi in features_grid:\n",
    "    mu, var = blr.predict(phi)\n",
    "    y_pred.append(mu)\n",
    "    y_std.append(np.sqrt(var))\n",
    "y_pred = np.array(y_pred)\n",
    "y_std = np.array(y_std)\n",
    "features_grid = model.extract_features(X_grid)\n",
    "\n",
    "y_pred = []\n",
    "y_std = []\n",
    "for phi in features_grid:\n",
    "    mu, var = blr.predict(phi)\n",
    "    y_pred.append(mu)\n",
    "    y_std.append(np.sqrt(var))\n",
    "y_pred = np.array(y_pred)\n",
    "y_std = np.array(y_std)\n",
    "\n",
    "ori_gga_data['y_pred'] = y_pred\n",
    "ori_gga_data['y_std'] = y_std\n",
    "\n",
    "plt.figure(figsize=(18, 7))\n",
    "x_idx = range(len(ori_gga_data))\n",
    "\n",
    "# True bandgap\n",
    "plt.scatter(x_idx, ori_gga_data['bandgap'], s=40, label='True bandgap', color='royalblue')\n",
    "# 예측값\n",
    "plt.scatter(x_idx, ori_gga_data['y_pred'], s=40, label='BLR prediction', color='orange', alpha=0.7)\n",
    "# 불확실성 범위\n",
    "plt.fill_between(\n",
    "    x_idx,\n",
    "    ori_gga_data['y_pred'] - ori_gga_data['y_std'],\n",
    "    ori_gga_data['y_pred'] + ori_gga_data['y_std'],\n",
    "    color='orange', alpha=0.2, label='Pred. std. dev.'\n",
    ")\n",
    "\n",
    "# 학습에 사용된 100개 포인트 인덱스 (검정색)\n",
    "train_indices = sorted(idx_sample)\n",
    "plt.scatter(\n",
    "    train_indices, ori_gga_data['bandgap'].iloc[train_indices],\n",
    "    s=110, color='black', label='Training points', zorder=10, marker='o'\n",
    ")\n",
    "\n",
    "plt.ylabel('Bandgap (HSE06)')\n",
    "plt.xlabel('Combinations (organic, cation, anion)')\n",
    "plt.xticks(x_idx, ori_gga_data['combo'], rotation=90, fontsize=7)\n",
    "plt.title('True Bandgap, BLR Prediction, Uncertainty (100 training points)')\n",
    "plt.legend()\n",
    "plt.xlim(-1, len(ori_gga_data))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# 실제값과 예측값\n",
    "y_true = ori_gga_data['bandgap'].values\n",
    "y_pred = ori_gga_data['y_pred'].values\n",
    "\n",
    "# R², MAE 계산\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "print(f\"R² score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
